{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gazpacho import get, Soup\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import timedelta, date\n",
    "\n",
    "import time \n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/points-from-2-pointers?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/points_from_2_ranks_2015_2021.csv\") ## change here\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/points-from-3-pointers?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/points_from_3_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/fastbreak-points-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/points_from_fastbreak_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/points-in-paint-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/points_in_paint_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/offensive-efficiency?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/offensive_efficiency_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/two-point-pct?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/two_pt_pct_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/three-point-pct?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/three_pt_pct_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/free-throw-pct?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.8)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.8)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.8)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.8)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.8)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.8)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/free_throw_pct_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/offensive-rebounds-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/offensive_rebound_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/defensive-rebounds-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.4)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.4)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.4)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.4)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.4)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.4)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/defensive_rebound_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/blocks-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/blocks_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/steals-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/steals_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/assists-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.6)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/assists_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/turnovers-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/turnovers_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/personal-fouls-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.65)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.65)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.65)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.65)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.65)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.65)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/fouls_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-points-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.52)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.52)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.52)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.52)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.52)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.52)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opponent_pts_per_game_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-points-from-2-pointers?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.46)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.46)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.46)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.46)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.46)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.46)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opponent_pts_from_2_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-points-from-3-pointers?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.71)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.71)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.71)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.71)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.71)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.71)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opponent_pts_from_3_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-fastbreak-points-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.36)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.36)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.36)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.36)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.36)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.36)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opponent_pts_from_fastbreak_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-points-in-paint-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.69)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.69)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.69)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.69)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.69)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.69)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opponent_pts_in_paint_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/defensive-efficiency?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.5)\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.7)\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.8)\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.4)\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(.9)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/defensive_efficiency_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay it worked\n"
     ]
    }
   ],
   "source": [
    "print(\"yay it worked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## second wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-three-point-pct?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_threepointpct_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-two-point-pct?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_twopointpct_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-offensive-rebounds-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_orebounds_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-defensive-rebounds-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_drebounds_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-blocks-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_blocks_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-steals-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_steals_ranks_2015_2021.csv\")\n",
    "## run time is about 26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-assists-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_assists_ranks_2015_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-turnovers-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_turnovers_ranks_2015_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = 1\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/opponent-personal-fouls-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'date': str(dates),\n",
    "            'rank': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'current_year_total': tr.find('td', {'class': 'text-right'})[0].text,\n",
    "            'last_three': tr.find('td', {'class': 'text-right'})[1].text,\n",
    "            'last_game': tr.find('td', {'class': 'text-right'})[2].text,\n",
    "            'home_score_avg': tr.find('td', {'class': 'text-right'})[3].text,\n",
    "            'away_score_avg': tr.find('td', {'class': 'text-right'})[4].text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "start_dt = date(2015, 11, 3)             \n",
    "end_dt = date(2016,4,13)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2016, 11, 1)             \n",
    "end_dt = date(2017,4,12)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2017, 10, 24)             \n",
    "end_dt = date(2018,4,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2018, 10, 23)             \n",
    "end_dt = date(2019,4,10)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2019, 10, 29)             \n",
    "end_dt = date(2020,3,11)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "start_dt = date(2020, 12, 30)             \n",
    "end_dt = date(2021,3,4)\n",
    "for i in daterange(start_dt, end_dt):\n",
    "    data.extend(scrape_page(dates=i))\n",
    "    time.sleep(random.uniform(.3, .7))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"data/opp_fouls_ranks_2015_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"worked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
