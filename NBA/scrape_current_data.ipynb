{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gazpacho import get, Soup\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import timedelta, date\n",
    "\n",
    "import time \n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = \"2021-04-28\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/assists-per-game?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "            'rank_assists': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df.to_csv(\"daily_data/assists-per-game.csv\")\n",
    "\n",
    "df1 = pd.read_csv(\"daily_data/assists-per-game.csv\")\n",
    "del df1[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"blocks-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_blocks': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df1, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"defensive-efficiency\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_deffeciency': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"defensive-rebounds-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_drebounds': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"personal-fouls-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_fouls': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"free-throw-pct\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_ft_pct': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"offensive-efficiency\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_oeffeciency': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-assists-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_assists': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-blocks-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_blocks': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-defensive-rebounds-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_drebounds': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-personal-fouls-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_fouls': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-offensive-rebounds-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_orebounds': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-fastbreak-points-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_ptsfastbreak': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-points-from-2-pointers\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_ptsfrom2': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-points-from-3-pointers\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_ptsfrom3': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-points-in-paint-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_ptsinpaint': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-points-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_ptspergame': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-steals-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_steals': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-three-point-pct\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_threepointpct': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-turnovers-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_turnovers': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"opponent-two-point-pct\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_opp_twopointpct': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"offensive-rebounds-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_orebounds': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"points-from-2-pointers\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_ptsfrom2': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"points-from-3-pointers\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_ptsfrom3': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"fastbreak-points-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_ptsfromfastbreak': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"points-in-paint-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_ptsinpaint': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"steals-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_steals': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"points-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_scoring': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"three-point-pct\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_threeptpct': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"turnovers-per-game\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_turnovers': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"two-point-pct\"\n",
    "def scrape_page(dates=dates):\n",
    "    url = 'https://www.teamrankings.com/nba/stat/' + str(cat) + '?date=' + str(dates) ## change here\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    \n",
    "    trs = soup.find('tr')\n",
    "    tr_pop = trs.pop(0)\n",
    "    tr = trs[0]\n",
    "    \n",
    "    def parse_tr(tr):\n",
    "        return {\n",
    "            'rank_twoptpct': tr.find('td', {'class': 'rank text-center'}).text,\n",
    "            'team': tr.find('td', {'class': 'text-left nowrap'}).text,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    rankers = [parse_tr(tr) for tr in trs]\n",
    "    return rankers\n",
    "\n",
    "data = []\n",
    "data.extend(scrape_page(dates=dates))\n",
    "time.sleep(.3)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df2 = pd.merge(df2, df, on=\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>rank_assists</th>\n",
       "      <th>rank_blocks</th>\n",
       "      <th>rank_deffeciency</th>\n",
       "      <th>rank_drebounds</th>\n",
       "      <th>rank_fouls</th>\n",
       "      <th>rank_ft_pct</th>\n",
       "      <th>rank_oeffeciency</th>\n",
       "      <th>rank_opp_assists</th>\n",
       "      <th>rank_opp_blocks</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_orebounds</th>\n",
       "      <th>rank_ptsfrom2</th>\n",
       "      <th>rank_ptsfrom3</th>\n",
       "      <th>rank_ptsfromfastbreak</th>\n",
       "      <th>rank_ptsinpaint</th>\n",
       "      <th>rank_steals</th>\n",
       "      <th>rank_scoring</th>\n",
       "      <th>rank_threeptpct</th>\n",
       "      <th>rank_turnovers</th>\n",
       "      <th>rank_twoptpct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Golden State</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denver</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Memphis</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Miami</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Washington</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LA Lakers</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Utah</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Boston</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Houston</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Okla City</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New York</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Portland</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            team  rank_assists rank_blocks rank_deffeciency rank_drebounds  \\\n",
       "0   Golden State             1          17                8             13   \n",
       "1         Denver             2          21               15             19   \n",
       "2        Memphis             3          19                9             10   \n",
       "3        Phoenix             4          27                6             18   \n",
       "4        Chicago             5          26               18              8   \n",
       "5      Charlotte             6          15               17             25   \n",
       "6       Brooklyn             7           8               25              7   \n",
       "7        Indiana             8           1               14             24   \n",
       "8    New Orleans             9          24               27              4   \n",
       "9          Miami            10          29                5             20   \n",
       "10     Milwaukee            11          20                7              1   \n",
       "11    Sacramento            12          14               30             30   \n",
       "12     Minnesota            13           4               28             27   \n",
       "13    Washington            14          30               21              5   \n",
       "14   San Antonio            15           7               11             16   \n",
       "15     LA Lakers            16           6                1             11   \n",
       "16   LA Clippers            17          28               10             12   \n",
       "17       Toronto            18           3               12             28   \n",
       "18       Detroit            19          10               16             26   \n",
       "19       Atlanta            20          18               20             17   \n",
       "20     Cleveland            21          16               22             29   \n",
       "21          Utah            22           5                3              2   \n",
       "22  Philadelphia            23           2                2              9   \n",
       "23        Boston            24          11               13             21   \n",
       "24       Houston            25           9               24             22   \n",
       "25        Dallas            26          23               19             14   \n",
       "26     Okla City            27          22               23              3   \n",
       "27       Orlando            28          25               26             15   \n",
       "28      New York            29          13                4              6   \n",
       "29      Portland            30          12               29             23   \n",
       "\n",
       "   rank_fouls rank_ft_pct rank_oeffeciency rank_opp_assists rank_opp_blocks  \\\n",
       "0          28          13               21                7               9   \n",
       "1           8           8                3               28               6   \n",
       "2          11          16               15               23              23   \n",
       "3          17           2                6                2               1   \n",
       "4          13           7               16               11              17   \n",
       "5           4          19               19               30              11   \n",
       "6          12           6                1               13              13   \n",
       "7          23          11               17               25              22   \n",
       "8           3          29               10               24              29   \n",
       "9          10          10               24               22               5   \n",
       "10          2          24                5               17              16   \n",
       "11         19          27               11               21               7   \n",
       "12         27          21               26               29              27   \n",
       "13         30          23               23               10              14   \n",
       "14          5          12               18               12              20   \n",
       "15         14          25               22               15               8   \n",
       "16         21           1                2                4               4   \n",
       "17         29           3               13               26              28   \n",
       "18         26          20               25               14              30   \n",
       "19         18           5                8                9              18   \n",
       "20          7          26               28               16              26   \n",
       "21          9           9                4                1               3   \n",
       "22         24          22               14                6              10   \n",
       "23         22          14               12                8              12   \n",
       "24         20          28               27               19              24   \n",
       "25         16          18                9                3               2   \n",
       "26          6          30               30               20              19   \n",
       "27          1          17               29               27              21   \n",
       "28         25          15               20                5              25   \n",
       "29         15           4                7               18              15   \n",
       "\n",
       "    ... rank_orebounds rank_ptsfrom2 rank_ptsfrom3 rank_ptsfromfastbreak  \\\n",
       "0   ...             29            22             7                     6   \n",
       "1   ...              6             6            12                    13   \n",
       "2   ...              2             1            25                     1   \n",
       "3   ...             28             9            13                    12   \n",
       "4   ...             21            10            17                    14   \n",
       "5   ...             10            25             8                    10   \n",
       "6   ...             26            14             6                     5   \n",
       "7   ...             25             7            19                     2   \n",
       "8   ...              1             3            27                     7   \n",
       "9   ...             30            26            15                    19   \n",
       "10  ...             11            11             4                     4   \n",
       "11  ...             17             5            20                     9   \n",
       "12  ...             12            19            14                    22   \n",
       "13  ...             20             2            28                    26   \n",
       "14  ...             22             4            29                    15   \n",
       "15  ...             18            12            24                    11   \n",
       "16  ...             16            18             5                    25   \n",
       "17  ...             23            29             3                     8   \n",
       "18  ...             15            23            21                    24   \n",
       "19  ...              7            15            16                    27   \n",
       "20  ...              8            13            30                    16   \n",
       "21  ...              4            30             1                    17   \n",
       "22  ...             14             8            26                     3   \n",
       "23  ...              5            16            11                    18   \n",
       "24  ...             24            27            10                    23   \n",
       "25  ...             27            21             9                    21   \n",
       "26  ...             19            24            18                    29   \n",
       "27  ...              9            20            23                    28   \n",
       "28  ...             13            17            22                    30   \n",
       "29  ...              3            28             2                    20   \n",
       "\n",
       "   rank_ptsinpaint rank_steals rank_scoring rank_threeptpct rank_turnovers  \\\n",
       "0               20           6           15              10             25   \n",
       "1               10           9            4               6             13   \n",
       "2                1           1           12              18              8   \n",
       "3               22          19           10               9              5   \n",
       "4                7          28           19              15             29   \n",
       "5               21          11           22               8             26   \n",
       "6                8          27            2               3             14   \n",
       "7                3           4           11              19             12   \n",
       "8                2          16            5              23             20   \n",
       "9               25          12           27              26             18   \n",
       "10              12           7            1               2             16   \n",
       "11               4          18            9              16              7   \n",
       "12              11           3           21              25             19   \n",
       "13               6          17            6              24             22   \n",
       "14              14          21           20              20              2   \n",
       "15               9          13           23              22             27   \n",
       "16              28          25            7               1              6   \n",
       "17              27           5           18              14             11   \n",
       "18              18          15           25              21             23   \n",
       "19              13          24           14              11              9   \n",
       "20               5           8           30              29             28   \n",
       "21              26          29            3               4             15   \n",
       "22              16           2           13              13             24   \n",
       "23              19          10           16              12             17   \n",
       "24              15          14           24              30             21   \n",
       "25              24          30           17              17              3   \n",
       "26              17          26           28              28             30   \n",
       "27              29          22           29              27              4   \n",
       "28              23          20           26               5             10   \n",
       "29              30          23            8               7              1   \n",
       "\n",
       "   rank_twoptpct  \n",
       "0             13  \n",
       "1              4  \n",
       "2             19  \n",
       "3              2  \n",
       "4              8  \n",
       "5             21  \n",
       "6              1  \n",
       "7             12  \n",
       "8              6  \n",
       "9              9  \n",
       "10             7  \n",
       "11             5  \n",
       "12            26  \n",
       "13            14  \n",
       "14            25  \n",
       "15            10  \n",
       "16            18  \n",
       "17            22  \n",
       "18            27  \n",
       "19            20  \n",
       "20            23  \n",
       "21            11  \n",
       "22            17  \n",
       "23            15  \n",
       "24            16  \n",
       "25             3  \n",
       "26            24  \n",
       "27            30  \n",
       "28            29  \n",
       "29            28  \n",
       "\n",
       "[30 rows x 32 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#48 sec run time\n",
    "df2.to_csv(\"daily_data/full_daily_ranks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
